{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKZaxmCu/1pchjvE312lcl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Koppurapu/MAIN/blob/main/IRS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nl_lHlEhpce7",
        "outputId": "c556046e-4046-4901-fbde-6e310e8f4c24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Required packages\n",
        "# pip install numpy opencv-python scikit-learn pillow matplotlib scipy scikit-image"
      ],
      "metadata": {
        "id": "QvSq_-pVqCI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#module_1:Create Feature Extractor Class\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.feature import local_binary_pattern, graycomatrix, graycoprops\n",
        "\n",
        "class FeatureExtractor:\n",
        "    def __init__(self):\n",
        "        self.feature_dim = 0\n",
        "\n",
        "    def extract_color_histogram(self, image, bins=32):\n",
        "        \"\"\"Extract color histogram in HSV space\"\"\"\n",
        "        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "        hist_h = cv2.calcHist([hsv], [0], None, [bins], [0, 180])\n",
        "        hist_s = cv2.calcHist([hsv], [1], None, [bins], [0, 256])\n",
        "        hist_v = cv2.calcHist([hsv], [2], None, [bins], [0, 256])\n",
        "\n",
        "        # Normalize\n",
        "        hist = np.concatenate([hist_h, hist_s, hist_v]).flatten()\n",
        "        hist = hist / (hist.sum() + 1e-7)\n",
        "        return hist\n",
        "\n",
        "    def extract_color_moments(self, image):\n",
        "        \"\"\"Extract color moments (mean, std, skewness)\"\"\"\n",
        "        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "        moments = []\n",
        "        for channel in cv2.split(hsv):\n",
        "            moments.append(np.mean(channel))\n",
        "            moments.append(np.std(channel))\n",
        "            moments.append(self._skewness(channel))\n",
        "        return np.array(moments)\n",
        "\n",
        "    def _skewness(self, channel):\n",
        "        mean = np.mean(channel)\n",
        "        std = np.std(channel)\n",
        "        if std == 0:\n",
        "            return 0\n",
        "        return np.mean(((channel - mean) / std) ** 3)\n",
        "\n",
        "    def extract_texture_lbp(self, image, P=8, R=1):\n",
        "        \"\"\"Extract Local Binary Pattern texture features\"\"\"\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        lbp = local_binary_pattern(gray, P, R, method='uniform')\n",
        "        hist, _ = np.histogram(lbp.ravel(), bins=P+2, range=(0, P+2))\n",
        "        hist = hist / (hist.sum() + 1e-7)\n",
        "        return hist\n",
        "\n",
        "    def extract_texture_glcm(self, image):\n",
        "        \"\"\"Extract GLCM texture features\"\"\"\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        # Quantize to reduce computation\n",
        "        gray = (gray / 16).astype(np.uint8)\n",
        "\n",
        "        glcm = graycomatrix(gray, [1], [0, np.pi/4, np.pi/2, 3*np.pi/4],\n",
        "                           levels=16, symmetric=True, normed=True)\n",
        "\n",
        "        # Extract properties\n",
        "        contrast = graycoprops(glcm, 'contrast').flatten()\n",
        "        dissimilarity = graycoprops(glcm, 'dissimilarity').flatten()\n",
        "        homogeneity = graycoprops(glcm, 'homogeneity').flatten()\n",
        "        energy = graycoprops(glcm, 'energy').flatten()\n",
        "        correlation = graycoprops(glcm, 'correlation').flatten()\n",
        "\n",
        "        return np.concatenate([contrast, dissimilarity, homogeneity,\n",
        "                              energy, correlation])\n",
        "\n",
        "    def extract_edge_histogram(self, image, bins=32):\n",
        "        \"\"\"Extract edge orientation histogram\"\"\"\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Sobel gradients\n",
        "        gx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
        "        gy = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
        "\n",
        "        magnitude = np.sqrt(gx**2 + gy**2)\n",
        "        orientation = np.arctan2(gy, gx)\n",
        "\n",
        "        # Create histogram of edge orientations\n",
        "        hist, _ = np.histogram(orientation[magnitude > np.percentile(magnitude, 75)],\n",
        "                              bins=bins, range=(-np.pi, np.pi))\n",
        "        hist = hist / (hist.sum() + 1e-7)\n",
        "        return hist\n",
        "\n",
        "    def extract_features(self, image):\n",
        "        \"\"\"Combine all features\"\"\"\n",
        "        color_hist = self.extract_color_histogram(image, bins=32)\n",
        "        color_moments = self.extract_color_moments(image)\n",
        "        texture_lbp = self.extract_texture_lbp(image)\n",
        "        texture_glcm = self.extract_texture_glcm(image)\n",
        "        edge_hist = self.extract_edge_histogram(image, bins=16)\n",
        "\n",
        "        features = np.concatenate([\n",
        "            color_hist,\n",
        "            color_moments,\n",
        "            texture_lbp,\n",
        "            texture_glcm,\n",
        "            edge_hist\n",
        "        ])\n",
        "\n",
        "        self.feature_dim = len(features)\n",
        "        return features"
      ],
      "metadata": {
        "id": "4sc-xM6lqCLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#module_1.2: Extract Features from Dataset\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "def extract_dataset_features(image_folder, output_file='features.npz'):\n",
        "    \"\"\"Extract features from all images in dataset\"\"\"\n",
        "    extractor = FeatureExtractor()\n",
        "\n",
        "    image_files = [f for f in os.listdir(image_folder)\n",
        "                   if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))]\n",
        "\n",
        "    features_list = []\n",
        "    filenames = []\n",
        "\n",
        "    print(\"Extracting features from images...\")\n",
        "    for img_file in tqdm(image_files):\n",
        "        img_path = os.path.join(image_folder, img_file)\n",
        "        image = cv2.imread(img_path)\n",
        "\n",
        "        if image is None:\n",
        "            continue\n",
        "\n",
        "        # Resize for consistency\n",
        "        image = cv2.resize(image, (256, 256))\n",
        "\n",
        "        features = extractor.extract_features(image)\n",
        "        features_list.append(features)\n",
        "        filenames.append(img_file)\n",
        "\n",
        "    features_array = np.array(features_list)\n",
        "\n",
        "    # Normalize features\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    scaler = StandardScaler()\n",
        "    features_normalized = scaler.fit_transform(features_array)\n",
        "\n",
        "    # Save\n",
        "    np.savez(output_file,\n",
        "             features=features_normalized,\n",
        "             filenames=filenames,\n",
        "             scaler_mean=scaler.mean_,\n",
        "             scaler_scale=scaler.scale_)\n",
        "\n",
        "    print(f\"Extracted {len(features_list)} feature vectors\")\n",
        "    print(f\"Feature dimension: {features_array.shape[1]}\")\n",
        "\n",
        "    return features_normalized, filenames, scaler"
      ],
      "metadata": {
        "id": "whNgH9qCqCOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#module_2:SVM-Based Retrieval System\n",
        "#2:Create Retrieval Engine\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics.pairwise import euclidean_distances, cosine_similarity\n",
        "\n",
        "class SVMRetrievalSystem:\n",
        "    def __init__(self, features, filenames, image_folder):\n",
        "        self.features = features\n",
        "        self.filenames = filenames\n",
        "        self.image_folder = image_folder\n",
        "        self.n_images = len(filenames)\n",
        "\n",
        "        # SVM model\n",
        "        self.svm = None\n",
        "        self.is_trained = False\n",
        "\n",
        "        # Feedback history\n",
        "        self.relevant_indices = []\n",
        "        self.irrelevant_indices = []\n",
        "        self.feedback_rounds = 0\n",
        "\n",
        "    def initial_retrieval(self, query_idx, top_k=20, metric='euclidean'):\n",
        "        \"\"\"Initial retrieval based on distance metric\"\"\"\n",
        "        query_features = self.features[query_idx].reshape(1, -1)\n",
        "\n",
        "        if metric == 'euclidean':\n",
        "            distances = euclidean_distances(query_features, self.features)[0]\n",
        "            # Lower distance = more similar\n",
        "            scores = -distances\n",
        "        elif metric == 'cosine':\n",
        "            similarities = cosine_similarity(query_features, self.features)[0]\n",
        "            scores = similarities\n",
        "\n",
        "        # Sort by scores (descending)\n",
        "        ranked_indices = np.argsort(scores)[::-1]\n",
        "\n",
        "        # Exclude query image itself\n",
        "        ranked_indices = ranked_indices[ranked_indices != query_idx]\n",
        "\n",
        "        return ranked_indices[:top_k], scores[ranked_indices[:top_k]]\n",
        "\n",
        "    def train_svm(self):\n",
        "        \"\"\"Train SVM on feedback\"\"\"\n",
        "        if len(self.relevant_indices) == 0:\n",
        "            print(\"No relevant feedback provided\")\n",
        "            return False\n",
        "\n",
        "        # Prepare training data\n",
        "        X_train = []\n",
        "        y_train = []\n",
        "\n",
        "        # Positive examples\n",
        "        for idx in self.relevant_indices:\n",
        "            X_train.append(self.features[idx])\n",
        "            y_train.append(1)\n",
        "\n",
        "        # Negative examples\n",
        "        for idx in self.irrelevant_indices:\n",
        "            X_train.append(self.features[idx])\n",
        "            y_train.append(-1)\n",
        "\n",
        "        X_train = np.array(X_train)\n",
        "        y_train = np.array(y_train)\n",
        "\n",
        "        # Handle class imbalance\n",
        "        n_pos = np.sum(y_train == 1)\n",
        "        n_neg = np.sum(y_train == -1)\n",
        "\n",
        "        if n_neg == 0:\n",
        "            # Need negative examples - use farthest images from positives\n",
        "            pos_features = self.features[self.relevant_indices]\n",
        "            pos_mean = np.mean(pos_features, axis=0, keepdims=True)\n",
        "            distances = euclidean_distances(pos_mean, self.features)[0]\n",
        "\n",
        "            # Add farthest images as pseudo-negatives\n",
        "            pseudo_neg_indices = np.argsort(distances)[-max(n_pos, 10):]\n",
        "            for idx in pseudo_neg_indices:\n",
        "                if idx not in self.relevant_indices:\n",
        "                    X_train = np.vstack([X_train, self.features[idx]])\n",
        "                    y_train = np.append(y_train, -1)\n",
        "\n",
        "            n_neg = np.sum(y_train == -1)\n",
        "\n",
        "        # Set class weights\n",
        "        class_weight = {1: n_neg / n_pos, -1: 1.0} if n_pos > 0 else None\n",
        "\n",
        "        # Train SVM with RBF kernel\n",
        "        self.svm = SVC(kernel='rbf', C=1.0, gamma='scale',\n",
        "                      class_weight=class_weight, probability=True)\n",
        "\n",
        "        self.svm.fit(X_train, y_train)\n",
        "        self.is_trained = True\n",
        "\n",
        "        return True\n",
        "\n",
        "    def svm_retrieval(self, top_k=20):\n",
        "        \"\"\"Retrieve using trained SVM\"\"\"\n",
        "        if not self.is_trained:\n",
        "            print(\"SVM not trained yet\")\n",
        "            return None, None\n",
        "\n",
        "        # Get decision function values (distance from hyperplane)\n",
        "        decision_values = self.svm.decision_function(self.features)\n",
        "\n",
        "        # Rank by decision values (higher = more relevant)\n",
        "        ranked_indices = np.argsort(decision_values)[::-1]\n",
        "\n",
        "        # Filter out already labeled images\n",
        "        labeled_indices = set(self.relevant_indices + self.irrelevant_indices)\n",
        "        ranked_indices = [idx for idx in ranked_indices\n",
        "                         if idx not in labeled_indices]\n",
        "\n",
        "        return ranked_indices[:top_k], decision_values[ranked_indices[:top_k]]\n",
        "\n",
        "    def add_feedback(self, relevant_list, irrelevant_list):\n",
        "        \"\"\"Add user feedback\"\"\"\n",
        "        self.relevant_indices.extend(relevant_list)\n",
        "        self.irrelevant_indices.extend(irrelevant_list)\n",
        "        self.feedback_rounds += 1\n",
        "\n",
        "        print(f\"Feedback round {self.feedback_rounds}:\")\n",
        "        print(f\"  Total relevant: {len(self.relevant_indices)}\")\n",
        "        print(f\"  Total irrelevant: {len(self.irrelevant_indices)}\")\n",
        "\n",
        "    def compute_precision(self, retrieved_indices, ground_truth_relevant):\n",
        "        \"\"\"Compute precision metric\"\"\"\n",
        "        retrieved_set = set(retrieved_indices)\n",
        "        relevant_set = set(ground_truth_relevant)\n",
        "\n",
        "        true_positives = len(retrieved_set.intersection(relevant_set))\n",
        "        precision = true_positives / len(retrieved_indices) if len(retrieved_indices) > 0 else 0\n",
        "\n",
        "        return precision"
      ],
      "metadata": {
        "id": "26PPubPvqCSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2.1:: Active Learning Component\n",
        "class ActiveLearningSelector:\n",
        "    \"\"\"Select most informative images for user feedback\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def uncertainty_sampling(svm_model, features, n_select=10):\n",
        "        \"\"\"Select images closest to decision boundary\"\"\"\n",
        "        decision_values = svm_model.decision_function(features)\n",
        "        uncertainties = np.abs(decision_values)\n",
        "\n",
        "        # Sort by uncertainty (lowest first)\n",
        "        uncertain_indices = np.argsort(uncertainties)\n",
        "\n",
        "        return uncertain_indices[:n_select]\n",
        "\n",
        "    @staticmethod\n",
        "    def diversity_sampling(features, candidate_indices, n_select=10):\n",
        "        \"\"\"Select diverse images using k-means\"\"\"\n",
        "        from sklearn.cluster import KMeans\n",
        "\n",
        "        candidate_features = features[candidate_indices]\n",
        "\n",
        "        if len(candidate_indices) <= n_select:\n",
        "            return candidate_indices\n",
        "\n",
        "        kmeans = KMeans(n_clusters=n_select, random_state=42)\n",
        "        kmeans.fit(candidate_features)\n",
        "\n",
        "        # Select image closest to each cluster center\n",
        "        selected = []\n",
        "        for i in range(n_select):\n",
        "            center = kmeans.cluster_centers_[i]\n",
        "            cluster_mask = kmeans.labels_ == i\n",
        "            cluster_indices = np.where(cluster_mask)[0]\n",
        "\n",
        "            if len(cluster_indices) > 0:\n",
        "                distances = euclidean_distances(\n",
        "                    center.reshape(1, -1),\n",
        "                    candidate_features[cluster_indices]\n",
        "                )[0]\n",
        "                closest_in_cluster = cluster_indices[np.argmin(distances)]\n",
        "                selected.append(candidate_indices[closest_in_cluster])\n",
        "\n",
        "        return selected"
      ],
      "metadata": {
        "id": "x8j0AkPYqCUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#module_3:User Interface\n",
        "# Create Interactive GUI\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.widgets import Button\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "class RetrievalGUI:\n",
        "    def __init__(self, retrieval_system):\n",
        "        self.system = retrieval_system\n",
        "        self.current_results = []\n",
        "        self.current_scores = []\n",
        "        self.selected_relevant = []\n",
        "        self.selected_irrelevant = []\n",
        "\n",
        "    def display_results(self, indices, scores, title=\"Retrieval Results\"):\n",
        "        \"\"\"Display retrieval results in grid\"\"\"\n",
        "        n_images = len(indices)\n",
        "        n_cols = 5\n",
        "        n_rows = (n_images + n_cols - 1) // n_cols\n",
        "\n",
        "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 3*n_rows))\n",
        "        fig.suptitle(title, fontsize=16)\n",
        "\n",
        "        axes = axes.flatten() if n_images > 1 else [axes]\n",
        "\n",
        "        for i, (idx, score) in enumerate(zip(indices, scores)):\n",
        "            if i >= len(axes):\n",
        "                break\n",
        "\n",
        "            img_path = os.path.join(self.system.image_folder,\n",
        "                                   self.system.filenames[idx])\n",
        "            img = cv2.imread(img_path)\n",
        "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            axes[i].imshow(img_rgb)\n",
        "            axes[i].set_title(f\"Score: {score:.3f}\", fontsize=8)\n",
        "            axes[i].axis('off')\n",
        "\n",
        "            # Add colored border for selected images\n",
        "            if idx in self.selected_relevant:\n",
        "                rect = mpatches.Rectangle((0, 0), img_rgb.shape[1]-1,\n",
        "                                         img_rgb.shape[0]-1,\n",
        "                                         linewidth=5, edgecolor='green',\n",
        "                                         facecolor='none')\n",
        "                axes[i].add_patch(rect)\n",
        "            elif idx in self.selected_irrelevant:\n",
        "                rect = mpatches.Rectangle((0, 0), img_rgb.shape[1]-1,\n",
        "                                         img_rgb.shape[0]-1,\n",
        "                                         linewidth=5, edgecolor='red',\n",
        "                                         facecolor='none')\n",
        "                axes[i].add_patch(rect)\n",
        "\n",
        "        # Hide empty subplots\n",
        "        for i in range(len(indices), len(axes)):\n",
        "            axes[i].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def run_interactive_session(self, query_idx, max_rounds=5):\n",
        "        \"\"\"Run interactive retrieval session\"\"\"\n",
        "        print(\"=\" * 60)\n",
        "        print(\"SVM-Based Image Retrieval with Relevance Feedback\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Initial retrieval\n",
        "        print(\"\\n[Round 0] Initial Retrieval...\")\n",
        "        results, scores = self.system.initial_retrieval(query_idx, top_k=20)\n",
        "\n",
        "        self.display_results(results, scores,\n",
        "                           title=\"Initial Retrieval (Round 0)\")\n",
        "\n",
        "        # Feedback rounds\n",
        "        for round_num in range(1, max_rounds + 1):\n",
        "            print(f\"\\n[Round {round_num}] Collecting Feedback...\")\n",
        "            print(\"Enter relevant image indices (comma-separated): \", end=\"\")\n",
        "            relevant_input = input().strip()\n",
        "\n",
        "            print(\"Enter irrelevant image indices (comma-separated): \", end=\"\")\n",
        "            irrelevant_input = input().strip()\n",
        "\n",
        "            # Parse input\n",
        "            relevant_list = []\n",
        "            if relevant_input:\n",
        "                relevant_list = [results[int(i)] for i in relevant_input.split(',')\n",
        "                               if i.strip().isdigit() and int(i) < len(results)]\n",
        "\n",
        "            irrelevant_list = []\n",
        "            if irrelevant_input:\n",
        "                irrelevant_list = [results[int(i)] for i in irrelevant_input.split(',')\n",
        "                                 if i.strip().isdigit() and int(i) < len(results)]\n",
        "\n",
        "            if not relevant_list and not irrelevant_list:\n",
        "                print(\"No feedback provided. Ending session.\")\n",
        "                break\n",
        "\n",
        "            # Add feedback\n",
        "            self.system.add_feedback(relevant_list, irrelevant_list)\n",
        "\n",
        "            # Train SVM\n",
        "            print(f\"\\n[Round {round_num}] Training SVM...\")\n",
        "            success = self.system.train_svm()\n",
        "\n",
        "            if not success:\n",
        "                print(\"Training failed. Ending session.\")\n",
        "                break\n",
        "\n",
        "            # SVM-based retrieval\n",
        "            print(f\"[Round {round_num}] Retrieving with SVM...\")\n",
        "            results, scores = self.system.svm_retrieval(top_k=20)\n",
        "\n",
        "            if results is None:\n",
        "                break\n",
        "\n",
        "            self.display_results(results, scores,\n",
        "                               title=f\"SVM Retrieval (Round {round_num})\")\n",
        "\n",
        "            # Ask to continue\n",
        "            print(f\"\\nContinue to round {round_num + 1}? (y/n): \", end=\"\")\n",
        "            continue_input = input().strip().lower()\n",
        "\n",
        "            if continue_input != 'y':\n",
        "                print(\"Session ended by user.\")\n",
        "                break\n",
        "\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(\"Retrieval session completed!\")\n",
        "        print(\"=\" * 60)"
      ],
      "metadata": {
        "id": "9vYTV46sqCWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3.1:Simplified Command-Line Interface\n",
        "def run_cli_session(retrieval_system, query_idx, max_rounds=5):\n",
        "    \"\"\"Simplified command-line interface\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"SVM Image Retrieval - Multi-Round Feedback\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Round 0: Initial retrieval\n",
        "    print(\"\\n>>> Round 0: Initial Retrieval\")\n",
        "    results, scores = retrieval_system.initial_retrieval(query_idx, top_k=20)\n",
        "\n",
        "    print(\"\\nTop 20 results:\")\n",
        "    for i, (idx, score) in enumerate(zip(results[:20], scores[:20])):\n",
        "        print(f\"  [{i}] {retrieval_system.filenames[idx]} (score: {score:.4f})\")\n",
        "\n",
        "    # Feedback rounds\n",
        "    for round_num in range(1, max_rounds + 1):\n",
        "        print(f\"\\n>>> Round {round_num}: Provide Feedback\")\n",
        "        print(\"Enter indices of RELEVANT images (e.g., 0,3,5): \", end=\"\")\n",
        "        rel_input = input().strip()\n",
        "\n",
        "        print(\"Enter indices of IRRELEVANT images (e.g., 1,2,4): \", end=\"\")\n",
        "        irrel_input = input().strip()\n",
        "\n",
        "        relevant_list = []\n",
        "        if rel_input:\n",
        "            relevant_list = [results[int(i)] for i in rel_input.split(',')\n",
        "                           if i.strip().isdigit() and 0 <= int(i) < len(results)]\n",
        "\n",
        "        irrelevant_list = []\n",
        "        if irrel_input:\n",
        "            irrelevant_list = [results[int(i)] for i in irrel_input.split(',')\n",
        "                             if i.strip().isdigit() and 0 <= int(i) < len(results)]\n",
        "\n",
        "        if not relevant_list:\n",
        "            print(\"Warning: No relevant feedback provided!\")\n",
        "            break\n",
        "\n",
        "        # Update system\n",
        "        retrieval_system.add_feedback(relevant_list, irrelevant_list)\n",
        "\n",
        "        # Train and retrieve\n",
        "        print(f\"\\nTraining SVM with {len(relevant_list)} relevant and {len(irrelevant_list)} irrelevant examples...\")\n",
        "        retrieval_system.train_svm()\n",
        "\n",
        "        results, scores = retrieval_system.svm_retrieval(top_k=20)\n",
        "\n",
        "        print(f\"\\nUpdated top 20 results:\")\n",
        "        for i, (idx, score) in enumerate(zip(results[:20], scores[:20])):\n",
        "            marker = \"âœ“\" if idx in retrieval_system.relevant_indices else \"\"\n",
        "            print(f\"  [{i}] {retrieval_system.filenames[idx]} (score: {score:.4f}) {marker}\")\n",
        "\n",
        "        print(f\"\\nContinue? (y/n): \", end=\"\")\n",
        "        if input().strip().lower() != 'y':\n",
        "            break\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Session complete!\")"
      ],
      "metadata": {
        "id": "thzSBYQOqCa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#module_4: Main Execution Script\n",
        "#Complete Main Script\n",
        "def main():\n",
        "    # Configuration\n",
        "    IMAGE_FOLDER = \"\"\n",
        "    FEATURES_FILE = \"features.npz\"\n",
        "\n",
        "    # Step 1: Extract features (run once)\n",
        "    if not os.path.exists(FEATURES_FILE):\n",
        "        print(\"Extracting features from dataset...\")\n",
        "        features, filenames, scaler = extract_dataset_features(\n",
        "            IMAGE_FOLDER, FEATURES_FILE\n",
        "        )\n",
        "    else:\n",
        "        print(\"Loading pre-computed features...\")\n",
        "        data = np.load(FEATURES_FILE)\n",
        "        features = data['features']\n",
        "        filenames = data['filenames']\n",
        "\n",
        "    print(f\"Loaded {len(features)} images\")\n",
        "    print(f\"Feature dimension: {features.shape[1]}\")\n",
        "\n",
        "    # Step 2: Initialize retrieval system\n",
        "    retrieval_system = SVMRetrievalSystem(features, filenames, IMAGE_FOLDER)\n",
        "\n",
        "    # Step 3: Select query image\n",
        "    print(\"\\nAvailable images:\")\n",
        "    for i, fname in enumerate(filenames[:20]):\n",
        "        print(f\"  [{i}] {fname}\")\n",
        "    print(\"  ...\")\n",
        "\n",
        "    query_idx = int(input(\"\\nEnter query image index: \"))\n",
        "\n",
        "    # Step 4: Run retrieval session\n",
        "    mode = input(\"Run with GUI (g) or CLI (c)? \").strip().lower()\n",
        "\n",
        "    if mode == 'g':\n",
        "        gui = RetrievalGUI(retrieval_system)\n",
        "        gui.run_interactive_session(query_idx, max_rounds=5)\n",
        "    else:\n",
        "        run_cli_session(retrieval_system, query_idx, max_rounds=5)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "wBiuCZQ-qCeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ... (rest of the code before main function)\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main entry point\"\"\"\n",
        "    import argparse\n",
        "\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description='SVM-Based Image Retrieval with Multi-Round Relevance Feedback'\n",
        "    )\n",
        "    parser.add_argument('--dataset', default='cifar10_images',\n",
        "                       help='Path to image dataset folder')\n",
        "    parser.add_argument('--features', default='features.npz',\n",
        "                       help='Path to save/load features')\n",
        "    parser.add_argument('--extract', action='store_true',\n",
        "                       help='Force feature extraction even if features file exists')\n",
        "    parser.add_argument('--query-idx', type=int, default=None,\n",
        "                       help='Query image index (if not provided, will prompt)')\n",
        "    parser.add_argument('--mode', choices=['interactive', 'evaluate', 'demo'],\n",
        "                       default='interactive',\n",
        "                       help='Running mode')\n",
        "    parser.add_argument('--max-rounds', type=int, default=5,\n",
        "                       help='Maximum number of feedback rounds')\n",
        "    parser.add_argument('--visualize', action='store_true',\n",
        "                       help='Show visual results (requires matplotlib)')\n",
        "\n",
        "    args = parser.parse_args([]) # Changed to parse an empty list\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"SVM-BASED IMAGE RETRIEVAL SYSTEM\")\n",
        "    print(\"Multi-Round Relevance Feedback\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # ... (rest of the main function code)\n"
      ],
      "metadata": {
        "id": "0_7sdRErqCgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb8923a2",
        "outputId": "96b39018-d362-4980-f0cd-1b9095a4b6b5"
      },
      "source": [
        "import os\n",
        "\n",
        "# Create the dataset folder if it doesn't exist\n",
        "IMAGE_FOLDER = 'cifar10_images'\n",
        "if not os.path.exists(IMAGE_FOLDER):\n",
        "    os.makedirs(IMAGE_FOLDER)\n",
        "    print(f\"Created empty folder: {IMAGE_FOLDER}\")\n",
        "else:\n",
        "    print(f\"Folder already exists: {IMAGE_FOLDER}\")\n",
        "\n",
        "# Now, call the main function from the previously defined cell.\n",
        "# Make sure all necessary classes and functions (FeatureExtractor, SVMRetrievalSystem, etc.)\n",
        "# are defined in cell 0_7sdRErqCgl (or earlier executed cells).\n",
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created empty folder: cifar10_images\n",
            "\n",
            "======================================================================\n",
            "SVM-BASED IMAGE RETRIEVAL SYSTEM\n",
            "Multi-Round Relevance Feedback\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bb1409a",
        "outputId": "81d46e1a-dc1f-44c0-894b-7793e3299925"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define CIFAR-10 class names\n",
        "cifar10_class_names = [\n",
        "    'airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "    'dog', 'frog', 'horse', 'ship', 'truck'\n",
        "]\n",
        "\n",
        "# Base folder for saving images\n",
        "IMAGE_FOLDER = 'cifar10_images'\n",
        "\n",
        "def save_cifar10_images(images, labels, dataset_type, base_folder):\n",
        "    print(f\"Saving {dataset_type} images...\")\n",
        "    for i in tqdm(range(len(images))):\n",
        "        img = images[i]\n",
        "        label = labels[i][0]  # Labels are in a nested array\n",
        "        class_name = cifar10_class_names[label]\n",
        "\n",
        "        # Create class-specific directory if it doesn't exist\n",
        "        class_folder = os.path.join(base_folder, class_name)\n",
        "        os.makedirs(class_folder, exist_ok=True)\n",
        "\n",
        "        # Save the image\n",
        "        img_path = os.path.join(class_folder, f'{dataset_type}_{i:05d}.png')\n",
        "        cv2.imwrite(img_path, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "# Assuming x_train, y_train, x_test, y_test are already loaded\n",
        "# from tensorflow.keras.datasets import cifar10\n",
        "# (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "save_cifar10_images(x_train, y_train, 'train', IMAGE_FOLDER)\n",
        "save_cifar10_images(x_test, y_test, 'test', IMAGE_FOLDER)\n",
        "\n",
        "print(f\"All CIFAR-10 images saved to '{IMAGE_FOLDER}' directory.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving train images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50000/50000 [00:14<00:00, 3520.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving test images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [00:02<00:00, 3372.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All CIFAR-10 images saved to 'cifar10_images' directory.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureExtractor:\n",
        "    \"\"\"Extract low-level features from images\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.feature_dim = 0\n",
        "\n",
        "    def extract_color_histogram(self, image, bins=32):\n",
        "        \"\"\"Extract color histogram in HSV space\"\"\"\n",
        "        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "        hist_h = cv2.calcHist([hsv], [0], None, [bins], [0, 180])\n",
        "        hist_s = cv2.calcHist([hsv], [1], None, [bins], [0, 256])\n",
        "        hist_v = cv2.calcHist([hsv], [2], None, [bins], [0, 256])\n",
        "\n",
        "        hist = np.concatenate([hist_h, hist_s, hist_v]).flatten()\n",
        "        hist = hist / (hist.sum() + 1e-7)\n",
        "        return hist\n",
        "\n",
        "    def extract_color_moments(self, image):\n",
        "        \"\"\"Extract color moments (mean, std, skewness)\"\"\"\n",
        "        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "        moments = []\n",
        "        for channel in cv2.split(hsv):\n",
        "            moments.append(np.mean(channel))\n",
        "            moments.append(np.std(channel))\n",
        "            moments.append(self._skewness(channel))\n",
        "        return np.array(moments)\n",
        "\n",
        "    def _skewness(self, channel):\n",
        "        mean = np.mean(channel)\n",
        "        std = np.std(channel)\n",
        "        if std == 0:\n",
        "            return 0\n",
        "        return np.mean(((channel - mean) / std) ** 3)\n",
        "\n",
        "    def extract_texture_lbp(self, image, P=8, R=1):\n",
        "        \"\"\"Extract Local Binary Pattern texture features\"\"\"\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        lbp = local_binary_pattern(gray, P, R, method='uniform')\n",
        "        hist, _ = np.histogram(lbp.ravel(), bins=P+2, range=(0, P+2))\n",
        "        hist = hist / (hist.sum() + 1e-7)\n",
        "        return hist\n",
        "\n",
        "    def extract_edge_histogram(self, image, bins=16):\n",
        "        \"\"\"Extract edge orientation histogram\"\"\"\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        gx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
        "        gy = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
        "\n",
        "        magnitude = np.sqrt(gx**2 + gy**2)\n",
        "        orientation = np.arctan2(gy, gx)\n",
        "\n",
        "        hist, _ = np.histogram(orientation[magnitude > np.percentile(magnitude, 75)],\n",
        "                              bins=bins, range=(-np.pi, np.pi))\n",
        "        hist = hist / (hist.sum() + 1e-7)\n",
        "        return hist\n",
        "\n",
        "    def extract_features(self, image):\n",
        "        \"\"\"Combine all features\"\"\"\n",
        "        color_hist = self.extract_color_histogram(image, bins=32)\n",
        "        color_moments = self.extract_color_moments(image)\n",
        "        texture_lbp = self.extract_texture_lbp(image)\n",
        "        edge_hist = self.extract_edge_histogram(image, bins=16)\n",
        "\n",
        "        features = np.concatenate([\n",
        "            color_hist,\n",
        "            color_moments,\n",
        "            texture_lbp,\n",
        "            edge_hist\n",
        "        ])\n",
        "\n",
        "        self.feature_dim = len(features)\n",
        "        return features\n",
        "\n",
        "def extract_dataset_features(image_folder, output_file='features.npz',\n",
        "                            resize_dim=(128, 128)):\n",
        "    \"\"\"Extract features from all images in dataset\"\"\"\n",
        "    extractor = FeatureExtractor()\n",
        "\n",
        "    # Get all image files\n",
        "    image_files = []\n",
        "    for root, dirs, files in os.walk(image_folder):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
        "                image_files.append(os.path.join(root, file))\n",
        "\n",
        "    features_list = []\n",
        "    filenames = []\n",
        "    categories = []\n",
        "\n",
        "    print(f\"Extracting features from {len(image_files)} images...\")\n",
        "    for img_path in tqdm(image_files):\n",
        "        image = cv2.imread(img_path)\n",
        "\n",
        "        if image is None:\n",
        "            continue\n",
        "\n",
        "        # Resize for consistency\n",
        "        image = cv2.resize(image, resize_dim)\n",
        "\n",
        "        # Extract features\n",
        "        features = extractor.extract_features(image)\n",
        "        features_list.append(features)\n",
        "\n",
        "        # Store relative path\n",
        "        rel_path = os.path.relpath(img_path, image_folder)\n",
        "        filenames.append(rel_path)\n",
        "\n",
        "        # Extract category from path\n",
        "        category = os.path.dirname(rel_path)\n",
        "        categories.append(category)\n",
        "\n",
        "    features_array = np.array(features_list)\n",
        "\n",
        "    # Normalize features\n",
        "    scaler = StandardScaler()\n",
        "    features_normalized = scaler.fit_transform(features_array)\n",
        "\n",
        "    # Save\n",
        "    np.savez(output_file,\n",
        "             features=features_normalized,\n",
        "             filenames=np.array(filenames),\n",
        "             categories=np.array(categories),\n",
        "             scaler_mean=scaler.mean_,\n",
        "             scaler_scale=scaler.scale_)\n",
        "\n",
        "    print(f\"âœ“ Extracted {len(features_list)} feature vectors\")\n",
        "    print(f\"âœ“ Feature dimension: {features_array.shape[1]}\")\n",
        "    print(f\"âœ“ Saved to: {output_file}\")\n",
        "\n",
        "    return features_normalized, filenames, categories, scaler"
      ],
      "metadata": {
        "id": "Ehs_c-NDqCin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SVMRetrievalSystem:\n",
        "    \"\"\"SVM-based image retrieval with relevance feedback\"\"\"\n",
        "\n",
        "    def __init__(self, features, filenames, categories, image_folder):\n",
        "        self.features = features\n",
        "        self.filenames = filenames\n",
        "        self.categories = categories\n",
        "        self.image_folder = image_folder\n",
        "        self.n_images = len(filenames)\n",
        "\n",
        "        # SVM model\n",
        "        self.svm = None\n",
        "        self.is_trained = False\n",
        "\n",
        "        # Feedback history\n",
        "        self.relevant_indices = []\n",
        "        self.irrelevant_indices = []\n",
        "        self.feedback_rounds = 0\n",
        "\n",
        "    def initial_retrieval(self, query_idx, top_k=20, metric='euclidean'):\n",
        "        \"\"\"Initial retrieval based on distance metric\"\"\"\n",
        "        query_features = self.features[query_idx].reshape(1, -1)\n",
        "\n",
        "        if metric == 'euclidean':\n",
        "            distances = euclidean_distances(query_features, self.features)[0]\n",
        "            scores = -distances  # Convert to similarity\n",
        "        elif metric == 'cosine':\n",
        "            scores = cosine_similarity(query_features, self.features)[0]\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown metric: {metric}\")\n",
        "\n",
        "        # Sort by scores (descending)\n",
        "        ranked_indices = np.argsort(scores)[::-1]\n",
        "\n",
        "        # Exclude query image itself\n",
        "        ranked_indices = ranked_indices[ranked_indices != query_idx]\n",
        "\n",
        "        return ranked_indices[:top_k], scores[ranked_indices[:top_k]]\n",
        "\n",
        "    def train_svm(self, C=1.0, gamma='scale'):\n",
        "        \"\"\"Train SVM on feedback\"\"\"\n",
        "        if len(self.relevant_indices) == 0:\n",
        "            print(\"âš  No relevant feedback provided\")\n",
        "            return False\n",
        "\n",
        "        # Prepare training data\n",
        "        X_train = []\n",
        "        y_train = []\n",
        "\n",
        "        # Positive examples\n",
        "        for idx in self.relevant_indices:\n",
        "            X_train.append(self.features[idx])\n",
        "            y_train.append(1)\n",
        "\n",
        "        # Negative examples\n",
        "        for idx in self.irrelevant_indices:\n",
        "            X_train.append(self.features[idx])\n",
        "            y_train.append(-1)\n",
        "\n",
        "        X_train = np.array(X_train)\n",
        "        y_train = np.array(y_train)\n",
        "\n",
        "        # Handle missing negative examples\n",
        "        n_pos = np.sum(y_train == 1)\n",
        "        n_neg = np.sum(y_train == -1)\n",
        "\n",
        "        if n_neg == 0:\n",
        "            # Use farthest images as pseudo-negatives\n",
        "            pos_features = self.features[self.relevant_indices]\n",
        "            pos_mean = np.mean(pos_features, axis=0, keepdims=True)\n",
        "            distances = euclidean_distances(pos_mean, self.features)[0]\n",
        "\n",
        "            pseudo_neg_indices = np.argsort(distances)[-max(n_pos * 2, 20):]\n",
        "            for idx in pseudo_neg_indices:\n",
        "                if idx not in self.relevant_indices:\n",
        "                    X_train = np.vstack([X_train, self.features[idx]])\n",
        "                    y_train = np.append(y_train, -1)\n",
        "\n",
        "            n_neg = np.sum(y_train == -1)\n",
        "            print(f\"  Added {n_neg} pseudo-negative examples\")\n",
        "\n",
        "        # Set class weights\n",
        "        class_weight = {1: n_neg / (n_pos + 1e-7), -1: 1.0}\n",
        "\n",
        "        # Train SVM\n",
        "        self.svm = SVC(kernel='rbf', C=C, gamma=gamma,\n",
        "                      class_weight=class_weight, probability=True)\n",
        "\n",
        "        self.svm.fit(X_train, y_train)\n",
        "        self.is_trained = True\n",
        "\n",
        "        return True\n",
        "\n",
        "    def svm_retrieval(self, top_k=20):\n",
        "        \"\"\"Retrieve using trained SVM\"\"\"\n",
        "        if not self.is_trained:\n",
        "            print(\"âš  SVM not trained yet\")\n",
        "            return None, None\n",
        "\n",
        "        # Get decision function values\n",
        "        decision_values = self.svm.decision_function(self.features)\n",
        "\n",
        "        # Rank by decision values\n",
        "        ranked_indices = np.argsort(decision_values)[::-1]\n",
        "\n",
        "        # Filter out already labeled images\n",
        "        labeled_indices = set(self.relevant_indices + self.irrelevant_indices)\n",
        "        ranked_indices = [idx for idx in ranked_indices\n",
        "                         if idx not in labeled_indices]\n",
        "\n",
        "        return ranked_indices[:top_k], decision_values[ranked_indices[:top_k]]\n",
        "\n",
        "    def add_feedback(self, relevant_list, irrelevant_list):\n",
        "        \"\"\"Add user feedback\"\"\"\n",
        "        self.relevant_indices.extend(relevant_list)\n",
        "        self.irrelevant_indices.extend(irrelevant_list)\n",
        "        self.feedback_rounds += 1\n",
        "\n",
        "        print(f\"\\nðŸ“Š Feedback Round {self.feedback_rounds}:\")\n",
        "        print(f\"   Relevant: {len(relevant_list)} (Total: {len(self.relevant_indices)})\")\n",
        "        print(f\"   Irrelevant: {len(irrelevant_list)} (Total: {len(self.irrelevant_indices)})\")\n",
        "\n",
        "    def compute_precision(self, retrieved_indices, ground_truth_relevant, k=20):\n",
        "        \"\"\"Compute precision@k\"\"\"\n",
        "        retrieved_k = retrieved_indices[:k]\n",
        "        relevant_set = set(ground_truth_relevant)\n",
        "        hits = sum(1 for idx in retrieved_k if idx in relevant_set)\n",
        "        return hits / k if k > 0 else 0\n",
        "\n",
        "    def get_image_path(self, idx):\n",
        "        \"\"\"Get full image path\"\"\"\n",
        "        return os.path.join(self.image_folder, self.filenames[idx])"
      ],
      "metadata": {
        "id": "uh7jjp5bqCl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_images_cli(retrieval_system, indices, scores, title=\"Results\"):\n",
        "    \"\"\"Display images in CLI with scores\"\"\"\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"{title:^70}\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    for i, (idx, score) in enumerate(zip(indices, scores)):\n",
        "        filename = retrieval_system.filenames[idx]\n",
        "        category = retrieval_system.categories[idx]\n",
        "\n",
        "        marker = \"\"\n",
        "        if idx in retrieval_system.relevant_indices:\n",
        "            marker = \" âœ“ RELEVANT\"\n",
        "        elif idx in retrieval_system.irrelevant_indices:\n",
        "            marker = \" âœ— IRRELEVANT\"\n",
        "\n",
        "        print(f\"[{i:2d}] Score: {score:7.4f} | {category:12s} | {filename}{marker}\")\n",
        "\n",
        "def run_cli_session(retrieval_system, query_idx, max_rounds=5):\n",
        "    \"\"\"Command-line interface for retrieval\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"SVM IMAGE RETRIEVAL - MULTI-ROUND RELEVANCE FEEDBACK\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Display query image\n",
        "    query_file = retrieval_system.filenames[query_idx]\n",
        "    query_category = retrieval_system.categories[query_idx]\n",
        "    print(f\"\\nðŸ” Query Image: {query_file}\")\n",
        "    print(f\"   Category: {query_category}\")\n",
        "\n",
        "    # Round 0: Initial retrieval\n",
        "    print(f\"\\n{'â”€'*70}\")\n",
        "    print(\"ROUND 0: Initial Retrieval (Distance-based)\")\n",
        "    print(f\"{'â”€'*70}\")\n",
        "\n",
        "    results, scores = retrieval_system.initial_retrieval(query_idx, top_k=20)\n",
        "    display_images_cli(retrieval_system, results, scores, \"Top 20 Initial Results\")\n",
        "\n",
        "    # Feedback rounds\n",
        "    for round_num in range(1, max_rounds + 1):\n",
        "        print(f\"\\n{'â”€'*70}\")\n",
        "        print(f\"ROUND {round_num}: Provide Feedback\")\n",
        "        print(f\"{'â”€'*70}\")\n",
        "\n",
        "        print(\"\\nEnter indices of RELEVANT images (e.g., 0,3,5 or 0-5): \", end=\"\")\n",
        "        rel_input = input().strip()\n",
        "\n",
        "        print(\"Enter indices of IRRELEVANT images (e.g., 1,2,4 or 6-10): \", end=\"\")\n",
        "        irrel_input = input().strip()\n",
        "\n",
        "        # Parse input\n",
        "        def parse_indices(input_str, max_idx):\n",
        "            indices = []\n",
        "            if not input_str:\n",
        "                return indices\n",
        "\n",
        "            parts = input_str.replace(' ', '').split(',')\n",
        "            for part in parts:\n",
        "                if '-' in part:\n",
        "                    start, end = map(int, part.split('-'))\n",
        "                    indices.extend(range(start, min(end + 1, max_idx)))\n",
        "                elif part.isdigit():\n",
        "                    idx = int(part)\n",
        "                    if 0 <= idx < max_idx:\n",
        "                        indices.append(idx)\n",
        "            return indices\n",
        "\n",
        "        rel_positions = parse_indices(rel_input, len(results))\n",
        "        irrel_positions = parse_indices(irrel_input, len(results))\n",
        "\n",
        "        relevant_list = [results[i] for i in rel_positions]\n",
        "        irrelevant_list = [results[i] for i in irrel_positions]\n",
        "\n",
        "        if not relevant_list:\n",
        "            print(\"\\nâš  No relevant feedback provided. Ending session.\")\n",
        "            break\n",
        "\n",
        "        # Add feedback\n",
        "        retrieval_system.add_feedback(relevant_list, irrelevant_list)\n",
        "\n",
        "        # Train SVM\n",
        "        print(f\"\\nðŸ”§ Training SVM...\")\n",
        "        success = retrieval_system.train_svm()\n",
        "\n",
        "        if not success:\n",
        "            break\n",
        "\n",
        "        # SVM retrieval\n",
        "        print(f\"ðŸ” Retrieving with SVM...\")\n",
        "        results, scores = retrieval_system.svm_retrieval(top_k=20)\n",
        "\n",
        "        if results is None:\n",
        "            break\n",
        "\n",
        "        display_images_cli(retrieval_system, results, scores,\n",
        "                          f\"Top 20 Results (SVM Round {round_num})\")\n",
        "\n",
        "        # Ask to continue\n",
        "        if round_num < max_rounds:\n",
        "            print(f\"\\n{'â”€'*70}\")\n",
        "            print(f\"Continue to Round {round_num + 1}? (y/n): \", end=\"\")\n",
        "            if input().strip().lower() != 'y':\n",
        "                break\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"SESSION COMPLETE\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Summary\n",
        "    print(f\"\\nTotal Feedback Collected:\")\n",
        "    print(f\"  âœ“ Relevant images: {len(retrieval_system.relevant_indices)}\")\n",
        "    print(f\"  âœ— Irrelevant images: {len(retrieval_system.irrelevant_indices)}\")\n",
        "    print(f\"  Total rounds: {retrieval_system.feedback_rounds}\")"
      ],
      "metadata": {
        "id": "l6mb1ubnqCpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_results(retrieval_system, indices, scores, title=\"Results\",\n",
        "                     save_path=None):\n",
        "    \"\"\"Visualize retrieval results in a grid\"\"\"\n",
        "    n_images = min(len(indices), 20)\n",
        "    n_cols = 5\n",
        "    n_rows = (n_images + n_cols - 1) // n_cols\n",
        "\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 3*n_rows))\n",
        "    fig.suptitle(title, fontsize=16, fontweight='bold')\n",
        "\n",
        "    if n_images == 1:\n",
        "        axes = [axes]\n",
        "    else:\n",
        "        axes = axes.flatten()\n",
        "\n",
        "    for i in range(n_cols * n_rows):\n",
        "        if i < n_images:\n",
        "            idx = indices[i]\n",
        "            score = scores[i]\n",
        "\n",
        "            img_path = retrieval_system.get_image_path(idx)\n",
        "            img = cv2.imread(img_path)\n",
        "\n",
        "            if img is not None:\n",
        "                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "                axes[i].imshow(img_rgb)\n",
        "\n",
        "                # Title with score and category\n",
        "                category = retrieval_system.categories[idx]\n",
        "                axes[i].set_title(f\"{category}\\nScore: {score:.3f}\",\n",
        "                                fontsize=9)\n",
        "\n",
        "                # Add border for labeled images\n",
        "                if idx in retrieval_system.relevant_indices:\n",
        "                    for spine in axes[i].spines.values():\n",
        "                        spine.set_edgecolor('green')\n",
        "                        spine.set_linewidth(4)\n",
        "                elif idx in retrieval_system.irrelevant_indices:\n",
        "                    for spine in axes[i].spines.values():\n",
        "                        spine.set_edgecolor('red')\n",
        "                        spine.set_linewidth(4)\n",
        "\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "        print(f\"âœ“ Visualization saved to: {save_path}\")\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "DSwdasIFqCxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_system(retrieval_system, query_idx, ground_truth_category,\n",
        "                   max_rounds=5):\n",
        "    \"\"\"Evaluate retrieval performance\"\"\"\n",
        "\n",
        "    # Get all images from same category as ground truth\n",
        "    ground_truth_indices = [i for i, cat in enumerate(retrieval_system.categories)\n",
        "                           if cat == ground_truth_category and i != query_idx]\n",
        "\n",
        "    results_history = {\n",
        "        'round': [],\n",
        "        'precision': [],\n",
        "        'recall': [],\n",
        "        'relevant_count': [],\n",
        "        'irrelevant_count': []\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"EVALUATION MODE\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Query Category: {ground_truth_category}\")\n",
        "    print(f\"Ground Truth Size: {len(ground_truth_indices)} relevant images\")\n",
        "\n",
        "    # Round 0\n",
        "    results, scores = retrieval_system.initial_retrieval(query_idx, top_k=100)\n",
        "    p = compute_metrics(results[:20], ground_truth_indices)\n",
        "\n",
        "    results_history['round'].append(0)\n",
        "    results_history['precision'].append(p['precision'])\n",
        "    results_history['recall'].append(p['recall'])\n",
        "    results_history['relevant_count'].append(0)\n",
        "    results_history['irrelevant_count'].append(0)\n",
        "\n",
        "    print(f\"\\nRound 0 - P@20: {p['precision']:.3f}, R@20: {p['recall']:.3f}\")\n",
        "\n",
        "    # Simulated feedback rounds\n",
        "    for round_num in range(1, max_rounds + 1):\n",
        "        # Simulate feedback: top-3 relevant, next-3 irrelevant\n",
        "        relevant_feedback = [idx for idx in results[:10]\n",
        "                           if idx in ground_truth_indices][:3]\n",
        "        irrelevant_feedback = [idx for idx in results[:10]\n",
        "                             if idx not in ground_truth_indices][:3]\n",
        "\n",
        "        if not relevant_feedback:\n",
        "            print(f\"No relevant images found in top-10. Stopping at round {round_num-1}\")\n",
        "            break\n",
        "\n",
        "        retrieval_system.add_feedback(relevant_feedback, irrelevant_feedback)\n",
        "        retrieval_system.train_svm()\n",
        "\n",
        "        results, scores = retrieval_system.svm_retrieval(top_k=100)\n",
        "        if results is None:\n",
        "            break\n",
        "\n",
        "        p = compute_metrics(results[:20], ground_truth_indices)\n",
        "\n",
        "        results_history['round'].append(round_num)\n",
        "        results_history['precision'].append(p['precision'])\n",
        "        results_history['recall'].append(p['recall'])\n",
        "        results_history['relevant_count'].append(len(retrieval_system.relevant_indices))\n",
        "        results_history['irrelevant_count'].append(len(retrieval_system.irrelevant_indices))\n",
        "\n",
        "        print(f\"Round {round_num} - P@20: {p['precision']:.3f}, R@20: {p['recall']:.3f}\")\n",
        "\n",
        "    # Plot results\n",
        "    plot_evaluation(results_history)\n",
        "\n",
        "    return results_history\n",
        "\n",
        "def compute_metrics(retrieved, ground_truth):\n",
        "    \"\"\"Compute precision and recall\"\"\"\n",
        "    retrieved_set = set(retrieved)\n",
        "    gt_set = set(ground_truth)\n",
        "\n",
        "    hits = len(retrieved_set.intersection(gt_set))\n",
        "\n",
        "    precision = hits / len(retrieved) if len(retrieved) > 0 else 0\n",
        "    recall = hits / len(gt_set) if len(gt_set) > 0 else 0\n",
        "\n",
        "    return {'precision': precision, 'recall': recall, 'hits': hits}\n",
        "\n",
        "def plot_evaluation(results_history):\n",
        "    \"\"\"Plot evaluation metrics\"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "    # Precision and Recall\n",
        "    axes[0].plot(results_history['round'], results_history['precision'],\n",
        "                marker='o', label='Precision@20', linewidth=2)\n",
        "    axes[0].plot(results_history['round'], results_history['recall'],\n",
        "                marker='s', label='Recall@20', linewidth=2)\n",
        "    axes[0].set_xlabel('Feedback Round', fontsize=12)\n",
        "    axes[0].set_ylabel('Score', fontsize=12)\n",
        "    axes[0].set_title('Precision and Recall vs. Feedback Rounds', fontsize=13, fontweight='bold')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "    axes[0].set_ylim([0, 1.0])\n",
        "\n",
        "    # Feedback counts\n",
        "    axes[1].bar(results_history['round'][1:], results_history['relevant_count'][1:],\n",
        "               label='Relevant', alpha=0.7, color='green')\n",
        "    axes[1].bar(results_history['round'][1:], results_history['irrelevant_count'][1:],\n",
        "               bottom=results_history['relevant_count'][1:],\n",
        "               label='Irrelevant', alpha=0.7, color='red')\n",
        "    axes[1].set_xlabel('Feedback Round', fontsize=12)\n",
        "    axes[1].set_ylabel('Cumulative Feedback Count', fontsize=12)\n",
        "    axes[1].set_title('Feedback Accumulation', fontsize=13, fontweight='bold')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('evaluation_results.png', dpi=150, bbox_inches='tight')\n",
        "    print(\"\\nâœ“ Evaluation plot saved: evaluation_results.png\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "2DC3Qaj7qCz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"Main entry point\"\"\"\n",
        "    import argparse\n",
        "\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description='SVM-Based Image Retrieval with Multi-Round Relevance Feedback'\n",
        "    )\n",
        "    parser.add_argument('--dataset', default='cifar10_images',\n",
        "                       help='Path to image dataset folder')\n",
        "    parser.add_argument('--features', default='features.npz',\n",
        "                       help='Path to save/load features')\n",
        "    parser.add_argument('--extract', action='store_true',\n",
        "                       help='Force feature extraction even if features file exists')\n",
        "    parser.add_argument('--query-idx', type=int, default=None,\n",
        "                       help='Query image index (if not provided, will prompt)')\n",
        "    parser.add_argument('--mode', choices=['interactive', 'evaluate', 'demo'],\n",
        "                       default='interactive',\n",
        "                       help='Running mode')\n",
        "    parser.add_argument('--max-rounds', type=int, default=5,\n",
        "                       help='Maximum number of feedback rounds')\n",
        "    parser.add_argument('--visualize', action='store_true',\n",
        "                       help='Show visual results (requires matplotlib)')\n",
        "\n",
        "    args = parser.parse_args([]) # Fix: Pass an empty list to avoid parsing kernel arguments\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"SVM-BASED IMAGE RETRIEVAL SYSTEM\")\n",
        "    print(\"Multi-Round Relevance Feedback\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Check if dataset exists\n",
        "    if not os.path.exists(args.dataset):\n",
        "        print(f\"\\nâŒ Dataset folder not found: {args.dataset}\")\n",
        "        print(\"\\nPlease run: python setup_dataset.py\")\n",
        "        return\n",
        "\n",
        "    # Load or extract features\n",
        "    if args.extract or not os.path.exists(args.features):\n",
        "        print(f\"\\nðŸ“Š Extracting features from: {args.dataset}\")\n",
        "        features, filenames, categories, scaler = extract_dataset_features(\n",
        "            args.dataset, args.features\n",
        "        )\n",
        "    else:\n",
        "        print(f\"\\nðŸ“Š Loading pre-computed features from: {args.features}\")\n",
        "        data = np.load(args.features, allow_pickle=True)\n",
        "        features = data['features']\n",
        "        filenames = data['filenames']\n",
        "        categories = data['categories']\n",
        "        print(f\"âœ“ Loaded {len(features)} feature vectors\")\n",
        "        print(f\"âœ“ Feature dimension: {features.shape[1]}\")\n",
        "\n",
        "    # Initialize retrieval system\n",
        "    retrieval_system = SVMRetrievalSystem(features, filenames, categories,\n",
        "                                         args.dataset)\n",
        "\n",
        "    # Get unique categories\n",
        "    unique_categories = sorted(set(categories))\n",
        "    print(f\"\\nðŸ“ Dataset Statistics:\")\n",
        "    print(f\"   Total images: {len(filenames)}\")\n",
        "    print(f\"   Categories: {len(unique_categories)}\")\n",
        "    for cat in unique_categories:\n",
        "        count = sum(1 for c in categories if c == cat)\n",
        "        print(f\"      - {cat}: {count} images\")\n",
        "\n",
        "    # Select query image\n",
        "    if args.query_idx is None:\n",
        "        print(f\"\\nðŸ” Select Query Image:\")\n",
        "        print(f\"   Sample images (first 20):\")\n",
        "        for i in range(min(20, len(filenames))):\n",
        "            print(f\"      [{i:3d}] {categories[i]:12s} - {filenames[i]}\")\n",
        "        print(\"   ...\")\n",
        "\n",
        "        query_idx = int(input(\"\\nEnter query image index: \"))\n",
        "    else:\n",
        "        query_idx = args.query_idx\n",
        "\n",
        "    if query_idx < 0 or query_idx >= len(filenames):\n",
        "        print(f\"âŒ Invalid query index: {query_idx}\")\n",
        "        return\n",
        "\n",
        "    # Run based on mode\n",
        "    if args.mode == 'interactive':\n",
        "        run_cli_session(retrieval_system, query_idx, max_rounds=args.max_rounds)\n",
        "\n",
        "    elif args.mode == 'evaluate':\n",
        "        query_category = categories[query_idx]\n",
        "        evaluate_system(retrieval_system, query_idx, query_category,\n",
        "                       max_rounds=args.max_rounds)\n",
        "\n",
        "    elif args.mode == 'demo':\n",
        "        print(\"\\nðŸŽ¬ Running Demo Mode...\")\n",
        "        results, scores = retrieval_system.initial_retrieval(query_idx, top_k=20)\n",
        "\n",
        "        if args.visualize:\n",
        "            visualize_results(retrieval_system, results, scores,\n",
        "                            \"Initial Retrieval Results\",\n",
        "                            save_path=\"demo_results.png\")\n",
        "        else:\n",
        "            display_images_cli(retrieval_system, results, scores,\n",
        "                             \"Initial Retrieval Results\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98fsRcoxqC2P",
        "outputId": "bf6b31cb-0cd1-4e82-a124-ef51f48e1b12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "SVM-BASED IMAGE RETRIEVAL SYSTEM\n",
            "Multi-Round Relevance Feedback\n",
            "======================================================================\n",
            "\n",
            "ðŸ“Š Loading pre-computed features from: features.npz\n",
            "âœ“ Loaded 60000 feature vectors\n",
            "âœ“ Feature dimension: 131\n",
            "\n",
            "ðŸ“ Dataset Statistics:\n",
            "   Total images: 60000\n",
            "   Categories: 10\n",
            "      - airplane: 6000 images\n",
            "      - automobile: 6000 images\n",
            "      - bird: 6000 images\n",
            "      - cat: 6000 images\n",
            "      - deer: 6000 images\n",
            "      - dog: 6000 images\n",
            "      - frog: 6000 images\n",
            "      - horse: 6000 images\n",
            "      - ship: 6000 images\n",
            "      - truck: 6000 images\n",
            "\n",
            "ðŸ” Select Query Image:\n",
            "   Sample images (first 20):\n",
            "      [  0] ship         - ship/test_05104.png\n",
            "      [  1] ship         - ship/train_11577.png\n",
            "      [  2] ship         - ship/train_31981.png\n",
            "      [  3] ship         - ship/train_13912.png\n",
            "      [  4] ship         - ship/train_33562.png\n",
            "      [  5] ship         - ship/train_24929.png\n",
            "      [  6] ship         - ship/train_35236.png\n",
            "      [  7] ship         - ship/train_19788.png\n",
            "      [  8] ship         - ship/train_49330.png\n",
            "      [  9] ship         - ship/train_41028.png\n",
            "      [ 10] ship         - ship/test_05814.png\n",
            "      [ 11] ship         - ship/train_07580.png\n",
            "      [ 12] ship         - ship/train_05806.png\n",
            "      [ 13] ship         - ship/train_48120.png\n",
            "      [ 14] ship         - ship/train_38952.png\n",
            "      [ 15] ship         - ship/train_46048.png\n",
            "      [ 16] ship         - ship/train_33756.png\n",
            "      [ 17] ship         - ship/train_41943.png\n",
            "      [ 18] ship         - ship/train_11309.png\n",
            "      [ 19] ship         - ship/train_49180.png\n",
            "   ...\n",
            "\n",
            "Enter query image index: 20\n",
            "\n",
            "======================================================================\n",
            "SVM IMAGE RETRIEVAL - MULTI-ROUND RELEVANCE FEEDBACK\n",
            "======================================================================\n",
            "\n",
            "ðŸ” Query Image: ship/train_46449.png\n",
            "   Category: ship\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "ROUND 0: Initial Retrieval (Distance-based)\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "======================================================================\n",
            "                        Top 20 Initial Results                        \n",
            "======================================================================\n",
            "[ 0] Score: -6.7259 | airplane     | airplane/train_35570.png\n",
            "[ 1] Score: -7.1911 | ship         | ship/train_37659.png\n",
            "[ 2] Score: -7.1922 | ship         | ship/train_24811.png\n",
            "[ 3] Score: -7.5685 | automobile   | automobile/train_30088.png\n",
            "[ 4] Score: -7.5831 | airplane     | airplane/train_08553.png\n",
            "[ 5] Score: -7.6902 | airplane     | airplane/train_39027.png\n",
            "[ 6] Score: -7.7072 | bird         | bird/train_36305.png\n",
            "[ 7] Score: -7.7196 | airplane     | airplane/train_14468.png\n",
            "[ 8] Score: -7.7423 | ship         | ship/train_28855.png\n",
            "[ 9] Score: -7.8100 | truck        | truck/train_46611.png\n",
            "[10] Score: -7.8117 | automobile   | automobile/train_23923.png\n",
            "[11] Score: -7.8520 | truck        | truck/train_06903.png\n",
            "[12] Score: -7.8738 | automobile   | automobile/train_31251.png\n",
            "[13] Score: -7.9254 | dog          | dog/train_47054.png\n",
            "[14] Score: -7.9261 | automobile   | automobile/train_38958.png\n",
            "[15] Score: -7.9537 | airplane     | airplane/train_16513.png\n",
            "[16] Score: -7.9928 | ship         | ship/train_05648.png\n",
            "[17] Score: -7.9931 | ship         | ship/train_31196.png\n",
            "[18] Score: -8.0256 | bird         | bird/train_49357.png\n",
            "[19] Score: -8.0678 | horse        | horse/train_17649.png\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "ROUND 1: Provide Feedback\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "Enter indices of RELEVANT images (e.g., 0,3,5 or 0-5): 0\n",
            "Enter indices of IRRELEVANT images (e.g., 1,2,4 or 6-10): 4\n",
            "\n",
            "ðŸ“Š Feedback Round 1:\n",
            "   Relevant: 1 (Total: 1)\n",
            "   Irrelevant: 1 (Total: 1)\n",
            "\n",
            "ðŸ”§ Training SVM...\n",
            "ðŸ” Retrieving with SVM...\n",
            "\n",
            "======================================================================\n",
            "                     Top 20 Results (SVM Round 1)                     \n",
            "======================================================================\n",
            "[ 0] Score: -0.1665 | airplane     | airplane/train_30297.png\n",
            "[ 1] Score: -0.1667 | airplane     | airplane/train_11029.png\n",
            "[ 2] Score: -0.2246 | cat          | cat/train_15412.png\n",
            "[ 3] Score: -0.2281 | airplane     | airplane/test_03112.png\n",
            "[ 4] Score: -0.2500 | truck        | truck/test_09927.png\n",
            "[ 5] Score: -0.2640 | bird         | bird/train_35800.png\n",
            "[ 6] Score: -0.2673 | airplane     | airplane/train_43998.png\n",
            "[ 7] Score: -0.2731 | ship         | ship/train_24945.png\n",
            "[ 8] Score: -0.2734 | deer         | deer/train_22513.png\n",
            "[ 9] Score: -0.2815 | airplane     | airplane/train_13894.png\n",
            "[10] Score: -0.2828 | ship         | ship/train_09951.png\n",
            "[11] Score: -0.2849 | ship         | ship/train_13325.png\n",
            "[12] Score: -0.2854 | airplane     | airplane/train_39447.png\n",
            "[13] Score: -0.2891 | ship         | ship/train_43381.png\n",
            "[14] Score: -0.2909 | ship         | ship/test_08602.png\n",
            "[15] Score: -0.2921 | ship         | ship/test_03226.png\n",
            "[16] Score: -0.2924 | deer         | deer/train_01254.png\n",
            "[17] Score: -0.2934 | airplane     | airplane/train_13473.png\n",
            "[18] Score: -0.2946 | ship         | ship/train_04466.png\n",
            "[19] Score: -0.2952 | ship         | ship/train_01699.png\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Continue to Round 2? (y/n): y\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "ROUND 2: Provide Feedback\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "Enter indices of RELEVANT images (e.g., 0,3,5 or 0-5): 5\n",
            "Enter indices of IRRELEVANT images (e.g., 1,2,4 or 6-10): 6\n",
            "\n",
            "ðŸ“Š Feedback Round 2:\n",
            "   Relevant: 1 (Total: 2)\n",
            "   Irrelevant: 1 (Total: 2)\n",
            "\n",
            "ðŸ”§ Training SVM...\n",
            "ðŸ” Retrieving with SVM...\n",
            "\n",
            "======================================================================\n",
            "                     Top 20 Results (SVM Round 2)                     \n",
            "======================================================================\n",
            "[ 0] Score: -0.2361 | airplane     | airplane/test_03112.png\n",
            "[ 1] Score: -0.2434 | ship         | ship/test_08602.png\n",
            "[ 2] Score: -0.2550 | airplane     | airplane/train_11029.png\n",
            "[ 3] Score: -0.2611 | truck        | truck/test_09927.png\n",
            "[ 4] Score: -0.2759 | frog         | frog/train_46535.png\n",
            "[ 5] Score: -0.2983 | airplane     | airplane/train_45088.png\n",
            "[ 6] Score: -0.3005 | airplane     | airplane/train_26296.png\n",
            "[ 7] Score: -0.3033 | airplane     | airplane/train_25816.png\n",
            "[ 8] Score: -0.3179 | deer         | deer/train_22513.png\n",
            "[ 9] Score: -0.3235 | airplane     | airplane/train_38670.png\n",
            "[10] Score: -0.3253 | ship         | ship/test_08951.png\n",
            "[11] Score: -0.3283 | ship         | ship/train_11948.png\n",
            "[12] Score: -0.3320 | deer         | deer/test_04675.png\n",
            "[13] Score: -0.3320 | airplane     | airplane/test_00975.png\n",
            "[14] Score: -0.3322 | airplane     | airplane/train_13894.png\n",
            "[15] Score: -0.3333 | deer         | deer/train_00020.png\n",
            "[16] Score: -0.3343 | ship         | ship/train_38567.png\n",
            "[17] Score: -0.3347 | bird         | bird/train_08770.png\n",
            "[18] Score: -0.3349 | deer         | deer/train_33688.png\n",
            "[19] Score: -0.3405 | ship         | ship/train_19587.png\n",
            "\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "Continue to Round 3? (y/n): n\n",
            "\n",
            "======================================================================\n",
            "SESSION COMPLETE\n",
            "======================================================================\n",
            "\n",
            "Total Feedback Collected:\n",
            "  âœ“ Relevant images: 2\n",
            "  âœ— Irrelevant images: 2\n",
            "  Total rounds: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "======================================================================\n",
        "SVM-BASED IMAGE RETRIEVAL SYSTEM\n",
        "Multi-Round Relevance Feedback\n",
        "======================================================================\n",
        "\n",
        "ðŸ“Š Loading pre-computed features from: features.npz\n",
        "âœ“ Loaded 60000 feature vectors\n",
        "âœ“ Feature dimension: 131\n",
        "\n",
        "ðŸ“ Dataset Statistics:\n",
        "   Total images: 60000\n",
        "   Categories: 10\n",
        "      - airplane: 6000 images\n",
        "      - automobile: 6000 images\n",
        "      - bird: 6000 images\n",
        "      - cat: 6000 images\n",
        "      - deer: 6000 images\n",
        "      - dog: 6000 images\n",
        "      - frog: 6000 images\n",
        "      - horse: 6000 images\n",
        "      - ship: 6000 images\n",
        "      - truck: 6000 images\n",
        "\n",
        "ðŸ” Select Query Image:\n",
        "   Sample images (first 20):\n",
        "      [  0] ship         - ship/test_05104.png\n",
        "      [  1] ship         - ship/train_11577.png\n",
        "      [  2] ship         - ship/train_31981.png\n",
        "      [  3] ship         - ship/train_13912.png\n",
        "      [  4] ship         - ship/train_33562.png\n",
        "      [  5] ship         - ship/train_24929.png\n",
        "      [  6] ship         - ship/train_35236.png\n",
        "      [  7] ship         - ship/train_19788.png\n",
        "      [  8] ship         - ship/train_49330.png\n",
        "      [  9] ship         - ship/train_41028.png\n",
        "      [ 10] ship         - ship/test_05814.png\n",
        "      [ 11] ship         - ship/train_07580.png\n",
        "      [ 12] ship         - ship/train_05806.png\n",
        "      [ 13] ship         - ship/train_48120.png\n",
        "      [ 14] ship         - ship/train_38952.png\n",
        "      [ 15] ship         - ship/train_46048.png\n",
        "      [ 16] ship         - ship/train_33756.png\n",
        "      [ 17] ship         - ship/train_41943.png\n",
        "      [ 18] ship         - ship/train_11309.png\n",
        "      [ 19] ship         - ship/train_49180.png\n",
        "   ...\n",
        "\n",
        "Enter query image index: 20\n",
        "\n",
        "======================================================================\n",
        "SVM IMAGE RETRIEVAL - MULTI-ROUND RELEVANCE FEEDBACK\n",
        "======================================================================\n",
        "\n",
        "ðŸ” Query Image: ship/train_46449.png\n",
        "   Category: ship\n",
        "\n",
        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "ROUND 0: Initial Retrieval (Distance-based)\n",
        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "======================================================================\n",
        "                        Top 20 Initial Results                        \n",
        "======================================================================\n",
        "[ 0] Score: -6.7259 | airplane     | airplane/train_35570.png\n",
        "[ 1] Score: -7.1911 | ship         | ship/train_37659.png\n",
        "[ 2] Score: -7.1922 | ship         | ship/train_24811.png\n",
        "[ 3] Score: -7.5685 | automobile   | automobile/train_30088.png\n",
        "[ 4] Score: -7.5831 | airplane     | airplane/train_08553.png\n",
        "[ 5] Score: -7.6902 | airplane     | airplane/train_39027.png\n",
        "[ 6] Score: -7.7072 | bird         | bird/train_36305.png\n",
        "[ 7] Score: -7.7196 | airplane     | airplane/train_14468.png\n",
        "[ 8] Score: -7.7423 | ship         | ship/train_28855.png\n",
        "[ 9] Score: -7.8100 | truck        | truck/train_46611.png\n",
        "[10] Score: -7.8117 | automobile   | automobile/train_23923.png\n",
        "[11] Score: -7.8520 | truck        | truck/train_06903.png\n",
        "[12] Score: -7.8738 | automobile   | automobile/train_31251.png\n",
        "[13] Score: -7.9254 | dog          | dog/train_47054.png\n",
        "[14] Score: -7.9261 | automobile   | automobile/train_38958.png\n",
        "[15] Score: -7.9537 | airplane     | airplane/train_16513.png\n",
        "[16] Score: -7.9928 | ship         | ship/train_05648.png\n",
        "[17] Score: -7.9931 | ship         | ship/train_31196.png\n",
        "[18] Score: -8.0256 | bird         | bird/train_49357.png\n",
        "[19] Score: -8.0678 | horse        | horse/train_17649.png\n",
        "\n",
        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "ROUND 1: Provide Feedback\n",
        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "Enter indices of RELEVANT images (e.g., 0,3,5 or 0-5): 0\n",
        "Enter indices of IRRELEVANT images (e.g., 1,2,4 or 6-10): 4\n",
        "\n",
        "ðŸ“Š Feedback Round 1:\n",
        "   Relevant: 1 (Total: 1)\n",
        "   Irrelevant: 1 (Total: 1)\n",
        "\n",
        "ðŸ”§ Training SVM...\n",
        "ðŸ” Retrieving with SVM...\n",
        "\n",
        "======================================================================\n",
        "                     Top 20 Results (SVM Round 1)                     \n",
        "======================================================================\n",
        "[ 0] Score: -0.1665 | airplane     | airplane/train_30297.png\n",
        "[ 1] Score: -0.1667 | airplane     | airplane/train_11029.png\n",
        "[ 2] Score: -0.2246 | cat          | cat/train_15412.png\n",
        "[ 3] Score: -0.2281 | airplane     | airplane/test_03112.png\n",
        "[ 4] Score: -0.2500 | truck        | truck/test_09927.png\n",
        "[ 5] Score: -0.2640 | bird         | bird/train_35800.png\n",
        "[ 6] Score: -0.2673 | airplane     | airplane/train_43998.png\n",
        "[ 7] Score: -0.2731 | ship         | ship/train_24945.png\n",
        "[ 8] Score: -0.2734 | deer         | deer/train_22513.png\n",
        "[ 9] Score: -0.2815 | airplane     | airplane/train_13894.png\n",
        "[10] Score: -0.2828 | ship         | ship/train_09951.png\n",
        "[11] Score: -0.2849 | ship         | ship/train_13325.png\n",
        "[12] Score: -0.2854 | airplane     | airplane/train_39447.png\n",
        "[13] Score: -0.2891 | ship         | ship/train_43381.png\n",
        "[14] Score: -0.2909 | ship         | ship/test_08602.png\n",
        "[15] Score: -0.2921 | ship         | ship/test_03226.png\n",
        "[16] Score: -0.2924 | deer         | deer/train_01254.png\n",
        "[17] Score: -0.2934 | airplane     | airplane/train_13473.png\n",
        "[18] Score: -0.2946 | ship         | ship/train_04466.png\n",
        "[19] Score: -0.2952 | ship         | ship/train_01699.png\n",
        "\n",
        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "Continue to Round 2? (y/n): y\n",
        "\n",
        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "ROUND 2: Provide Feedback\n",
        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "Enter indices of RELEVANT images (e.g., 0,3,5 or 0-5): 5\n",
        "Enter indices of IRRELEVANT images (e.g., 1,2,4 or 6-10): 6\n",
        "\n",
        "ðŸ“Š Feedback Round 2:\n",
        "   Relevant: 1 (Total: 2)\n",
        "   Irrelevant: 1 (Total: 2)\n",
        "\n",
        "ðŸ”§ Training SVM...\n",
        "ðŸ” Retrieving with SVM...\n",
        "\n",
        "======================================================================\n",
        "                     Top 20 Results (SVM Round 2)                     \n",
        "======================================================================\n",
        "[ 0] Score: -0.2361 | airplane     | airplane/test_03112.png\n",
        "[ 1] Score: -0.2434 | ship         | ship/test_08602.png\n",
        "[ 2] Score: -0.2550 | airplane     | airplane/train_11029.png\n",
        "[ 3] Score: -0.2611 | truck        | truck/test_09927.png\n",
        "[ 4] Score: -0.2759 | frog         | frog/train_46535.png\n",
        "[ 5] Score: -0.2983 | airplane     | airplane/train_45088.png\n",
        "[ 6] Score: -0.3005 | airplane     | airplane/train_26296.png\n",
        "[ 7] Score: -0.3033 | airplane     | airplane/train_25816.png\n",
        "[ 8] Score: -0.3179 | deer         | deer/train_22513.png\n",
        "[ 9] Score: -0.3235 | airplane     | airplane/train_38670.png\n",
        "[10] Score: -0.3253 | ship         | ship/test_08951.png\n",
        "[11] Score: -0.3283 | ship         | ship/train_11948.png\n",
        "[12] Score: -0.3320 | deer         | deer/test_04675.png\n",
        "[13] Score: -0.3320 | airplane     | airplane/test_00975.png\n",
        "[14] Score: -0.3322 | airplane     | airplane/train_13894.png\n",
        "[15] Score: -0.3333 | deer         | deer/train_00020.png\n",
        "[16] Score: -0.3343 | ship         | ship/train_38567.png\n",
        "[17] Score: -0.3347 | bird         | bird/train_08770.png\n",
        "[18] Score: -0.3349 | deer         | deer/train_33688.png\n",
        "[19] Score: -0.3405 | ship         | ship/train_19587.png\n",
        "\n",
        "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "Continue to Round 3? (y/n): n\n",
        "\n",
        "======================================================================\n",
        "SESSION COMPLETE\n",
        "======================================================================\n",
        "\n",
        "Total Feedback Collected:\n",
        "  âœ“ Relevant images: 2\n",
        "  âœ— Irrelevant images: 2\n",
        "  Total rounds: 2\n"
      ],
      "metadata": {
        "id": "q29sNB0eCbRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_0XzcX9tqC6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M8uP_flfqC80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nKu34yyGqC-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZbHY_MEuqDBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rqNBylklqDDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0je0YQSaqDG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_xhDJlRYqDKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CcU4s-uPqDMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PldTJ4W-qDP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WbjnQnJvqDSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tWDgj-NVqDU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dhsYrkoIqDXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_WsujW4nqDas"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}